{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.大作业以2-3人为一组完成，提交材料包括PPT（最后一次课将会展示课程成果）+ 最终的大作业报告（需组内各成员单独提交，内容为本人在课程大作业中的贡献以及对大作业问题的思考) + 提交包含分工情况及组内各成员工作量占比的表格。分工表格需组内所有成员签字确认；\n",
    "\n",
    "2.禁止抄袭，发现雷同，所有雷同提交分数除以2；\n",
    "\n",
    "3.写清楚大作业中的贡献和创新点，若使用开源代码和论文中的方法，在报告中必须注明（不可作为本人创新点），发现不标注引用，分数除以2。\n",
    "\n",
    "最后一次课展示说明：\n",
    "1.样例\n",
    "PPT例子：https://www.sohu.com/a/166633625_642762\n",
    "2.展示时间限制：\n",
    "展示时间为最后一节课，展示时间为6分钟讲+2分钟同学助教老师自由提问\n",
    "\n",
    "大作业报告：强调个人对问题的理解，以及贡献，建议增加在提问反馈之后的改进结果。\n",
    "\n",
    "最终评分为:30%展示评分+70%大作业报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题描述(Out-of-Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度神经网络通常采用独立同分布(Independent-Identically)的假设进行训练，即假设测试数据分布与训练数据分布相似。然而，当用于实际任务时，这一假设并不成立，导致其性能显著下降。虽然这种性能下降对于产品推荐等宽容性大的应用是可以接受的，但在医学等宽容性小的领域使用此类系统是危险的，因为它们可能导致严重事故。理想的人工智能系统应尽可能在分布外（Out-of-Distribution）的情况下有较强的分部外泛化能力。而提高分布外泛化的关键点，就是如何让模型学习到数据中的causal feature。  \n",
    "一个简单的例子：以猫狗二分类为例，如果训练集中所有狗都在草地上，所有的猫都在沙发上，而测试集中所有的狗在沙发上，所有的猫在草地上，那么模型在没有测试集信息的情况下，很有可能根据训练集的信息把草地和狗联系在了一起，沙发和猫联系在了一起，当模型在测试集上测试时将会把在沙发上的狗误认为是猫。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初级部分：探索OOD算法在多样性偏移数据上的表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多样性偏移 (Diversity Shift)\n",
    "Colored MNIST是一个分布外泛化领域中常用的数据集，在该数据集中，训练集和测试集之间存在分布外泛化（Out-of-Distribution）情况。\n",
    "在初级部分，我们先给出Colored MNIST 的一个简单变体。即训练数据和测试数据数字对应不同的颜色，即数据具有多样的非因果信息，这种训练与测试数据中出现不相交的非因果信息的现象，我们称之为多样性偏移 (diversity Shift)。\n",
    "具体而言，在三种训练环境中，数据分别为红色数字黑色背景、绿色数字黑色背景、白色数字黑色背景。在测试阶段，数据分别为黄色数字白色背景、蓝色数字白色背景。\n",
    "\n",
    "要求：\n",
    "1.在数据集上训练和测试LeNet。  \n",
    "\n",
    "【OOD算法性能评价准则：在训练过程中只能接触训练集，不能在测试集上进行调参或者模型选择】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision.datasets.utils as dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_grayscale_arr(arr, forground_color, background_color):\n",
    "    \"\"\"Converts grayscale image\"\"\"\n",
    "    assert arr.ndim == 2\n",
    "    dtype = arr.dtype\n",
    "    h, w = arr.shape\n",
    "    arr = np.reshape(arr, [h, w, 1])\n",
    "    if background_color == \"black\":\n",
    "        if forground_color == \"red\":\n",
    "            arr = np.concatenate([arr,\n",
    "                              np.zeros((h, w, 2), dtype=dtype)], axis=2)\n",
    "        elif forground_color == \"green\":\n",
    "            arr = np.concatenate([np.zeros((h, w, 1), dtype=dtype),\n",
    "                              arr,\n",
    "                              np.zeros((h, w, 1), dtype=dtype)], axis=2)\n",
    "        elif forground_color == \"white\":\n",
    "            arr = np.concatenate([arr, arr, arr], axis=2)\n",
    "    else:\n",
    "        if forground_color == \"yellow\":\n",
    "            arr = np.concatenate([arr, arr, np.zeros((h, w, 1), dtype=dtype)], axis=2)\n",
    "        else:\n",
    "            arr = np.concatenate([np.zeros((h, w, 2), dtype=dtype), arr], axis=2)\n",
    "\n",
    "        c = [255, 255, 255]\n",
    "        arr[:, :, 0] = (255 - arr[:, :, 0]) / 255 * c[0]\n",
    "        arr[:, :, 1] = (255 - arr[:, :, 1]) / 255 * c[1]\n",
    "        arr[:, :, 2] = (255 - arr[:, :, 2]) / 255 * c[2]\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "class ColoredMNIST(datasets.VisionDataset):\n",
    "\n",
    "    def __init__(self, root='./data', env='train1', transform=None, target_transform=None):\n",
    "        super(ColoredMNIST, self).__init__(root, transform=transform,\n",
    "                                           target_transform=target_transform)\n",
    "\n",
    "        self.prepare_colored_mnist()\n",
    "        if env in ['train1', 'train2', 'train3', 'test1', 'test2']:\n",
    "            self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', env) + '.pt')\n",
    "        elif env == 'all_train':\n",
    "            self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', 'train1.pt')) + \\\n",
    "                                     torch.load(os.path.join(self.root, 'ColoredMNIST', 'train2.pt')) + \\\n",
    "                                     torch.load(os.path.join(self.root, 'ColoredMNIST', 'train3.pt'))\n",
    "        else:\n",
    "            raise RuntimeError(f'{env} env unknown. Valid envs are train1, train2, train3, test1, test2, and all_train')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "    Args:\n",
    "        index (int): Index\n",
    "\n",
    "    Returns:\n",
    "        tuple: (image, target) where target is index of the target class.\n",
    "    \"\"\"\n",
    "        img, target = self.data_label_tuples[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_label_tuples)\n",
    "\n",
    "    def prepare_colored_mnist(self):\n",
    "        colored_mnist_dir = os.path.join(self.root, 'ColoredMNIST')\n",
    "        if os.path.exists(os.path.join(colored_mnist_dir, 'train1.pt')) \\\n",
    "                and os.path.exists(os.path.join(colored_mnist_dir, 'train2.pt')) \\\n",
    "                and os.path.exists(os.path.join(colored_mnist_dir, 'train3.pt')) \\\n",
    "                and os.path.exists(os.path.join(colored_mnist_dir, 'test1.pt')) \\\n",
    "                and os.path.exists(os.path.join(colored_mnist_dir, 'test2.pt')):\n",
    "            print('Colored MNIST dataset already exists')\n",
    "            return\n",
    "\n",
    "        print('Preparing Colored MNIST')\n",
    "        train_mnist = datasets.mnist.MNIST(self.root, train=True, download=True)\n",
    "\n",
    "        train1_set = []\n",
    "        train2_set = []\n",
    "        train3_set = []\n",
    "        test1_set, test2_set = [], []\n",
    "        for idx, (im, label) in enumerate(train_mnist):\n",
    "            if idx % 10000 == 0:\n",
    "                print(f'Converting image {idx}/{len(train_mnist)}')\n",
    "            im_array = np.array(im)\n",
    "            \n",
    "            # Assign a binary label y to the image based on the digit\n",
    "            binary_label = 0 if label < 5 else 1\n",
    "\n",
    "            # Color the image according to its environment label\n",
    "\n",
    "            if idx < 10000:\n",
    "                colored_arr = color_grayscale_arr(im_array, forground_color = \"red\", background_color = \"black\")\n",
    "                train1_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "            elif idx < 20000:\n",
    "                colored_arr = color_grayscale_arr(im_array, forground_color = \"green\", background_color = \"black\")\n",
    "                train2_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "            elif idx < 30000:\n",
    "                colored_arr = color_grayscale_arr(im_array, forground_color = \"white\", background_color = \"black\")\n",
    "                train3_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "            elif idx < 45000:\n",
    "                colored_arr = color_grayscale_arr(im_array, forground_color = \"yellow\", background_color = \"white\")\n",
    "                test1_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "            else:\n",
    "                colored_arr = color_grayscale_arr(im_array, forground_color = \"blue\", background_color = \"white\")\n",
    "                test2_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "                \n",
    "            # Image.fromarray(colored_arr).save('./data/sample/{}.png'.format(idx))\n",
    "\n",
    "        if not os.path.exists(colored_mnist_dir):\n",
    "            os.makedirs(colored_mnist_dir)\n",
    "        torch.save(train1_set, os.path.join(colored_mnist_dir, 'train1.pt'))\n",
    "        torch.save(train2_set, os.path.join(colored_mnist_dir, 'train2.pt'))\n",
    "        torch.save(train3_set, os.path.join(colored_mnist_dir, 'train3.pt'))\n",
    "        torch.save(test1_set, os.path.join(colored_mnist_dir, 'test1.pt'))\n",
    "        torch.save(test2_set, os.path.join(colored_mnist_dir, 'test2.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中级部分:  数据增广与分析\n",
    "1.尝试对数据集进行增广，比如将训练集扩充为不同颜色的数据集等,并进行实验，得到测试效果\n",
    "\n",
    "2.二选一：\n",
    "\n",
    "- 可视化分析模型的效果，例如可视化分析模型准确性，做参数敏感性分析，注意力分析（gradcam）等\n",
    "  \n",
    "- 使用Django框架，制作网站，实现上传图片，输出分类结果的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高级部分(选做，开放性问题)：\n",
    "1.从以下分布外泛化算法论文中选取一篇论文阅读并复现测试算法效果：\n",
    "\n",
    "    - Invariant risk minimization (IRM)\n",
    "    - Domain-Adversarial Training of Neural Networks (DANN)    \n",
    "    - Out-of-Distribution Generalization via Risk Extrapolation (VREx)  \n",
    "    - Learning Explanations that are Hard to Vary (AndMask)  \n",
    "    - Self-Challenging Improves Cross-Domain Generalization (RSC)  \n",
    "\n",
    "2.在不使用数据增广的情况下，是否可以把实验过程中发现可以提高泛化性能的做法总结一些经验性的原则，并设计一个新的通用算法，提高深度神经网络的泛化性能，并在mnist数据集的变体上进行验证，并说明这么做的原因【实验和理论都可】。【mnist变体指保持训练集不变，对测试集做变换（例如改变颜色、形状、增加噪声等）】\n",
    "如果用到公开算法，需要引用并注明新的贡献点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
